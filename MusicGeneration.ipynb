{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya02shah/MusicGeneration/blob/main/MusicGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1AQMikGKLQj",
        "outputId": "5f8fff8c-25fe-4af9-e9d4-fe757220b7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mitdeeplearning in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mitdeeplearning) (1.22.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from mitdeeplearning) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mitdeeplearning) (4.65.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from mitdeeplearning) (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->mitdeeplearning) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->mitdeeplearning) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "  !pip install mitdeeplearning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XetKHg21ALO0"
      },
      "source": [
        "##Importing Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSIEacgKKbyo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import mitdeeplearning as mdl\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W3BbIx2ARNI"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6BKAWgLKs_t",
        "outputId": "a5aa8a61-1cc7-4377-8ab9-43b55a030e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 817 songs in text\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "songs = mdl.lab1.load_training_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRcv52irV1qW"
      },
      "outputs": [],
      "source": [
        "!apt-get -y install abcmidi timidity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzUXk1kaKvpE",
        "outputId": "a0d2ce16-e65a-4aa3-cbef-9f4ae1e299f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example song: \n",
            "X:1\n",
            "T:Alexander's\n",
            "Z: id:dc-hornpipe-1\n",
            "M:C|\n",
            "L:1/8\n",
            "K:D Major\n",
            "(3ABc|dAFA DFAd|fdcd FAdf|gfge fefd|(3efe (3dcB A2 (3ABc|!\n",
            "dAFA DFAd|fdcd FAdf|gfge fefd|(3efe dc d2:|!\n",
            "AG|FAdA FAdA|GBdB GBdB|Acec Acec|dfaf gecA|!\n",
            "FAdA FAdA|GBdB GBdB|Aceg fefd|(3efe dc d2:|!\n"
          ]
        }
      ],
      "source": [
        "example_song = songs[0]\n",
        "print(\"\\nExample song: \")\n",
        "print(example_song)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuXYHM0B13FJ"
      },
      "outputs": [],
      "source": [
        "waveform = mdl.lab1.play_song(example_song)\n",
        "if waveform:\n",
        "   ipythondisplay.display(waveform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNxmfEBVKxuR",
        "outputId": "a6f41706-f2db-4909-c893-edb8249887f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 83 unique characters in the dataset\n"
          ]
        }
      ],
      "source": [
        "songs_joined = \"\\n\\n\".join(songs)\n",
        "\n",
        "# Finding all unique characters in the joined string\n",
        "vocab = sorted(set(songs_joined))\n",
        "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6teveksK34d"
      },
      "outputs": [],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQpVstEQAaKK"
      },
      "source": [
        "##Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRjA2bbnAd1V"
      },
      "source": [
        "####Vectorise the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmVLTrreK7R8",
        "outputId": "83dfddfa-93ad-42c0-c2eb-4ec1a3e6304f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, \"'\": 5, '(': 6, ')': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '<': 23, '=': 24, '>': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, '[': 52, ']': 53, '^': 54, '_': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81, '|': 82}\n"
          ]
        }
      ],
      "source": [
        "char_to_index = dict((j,i) for i,j in enumerate(vocab))\n",
        "print(char_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifCl2eIcUm2P",
        "outputId": "92a69127-e86c-4f3f-c8b6-cee7b79af651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: \"'\", 6: '(', 7: ')', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: '<', 24: '=', 25: '>', 26: 'A', 27: 'B', 28: 'C', 29: 'D', 30: 'E', 31: 'F', 32: 'G', 33: 'H', 34: 'I', 35: 'J', 36: 'K', 37: 'L', 38: 'M', 39: 'N', 40: 'O', 41: 'P', 42: 'Q', 43: 'R', 44: 'S', 45: 'T', 46: 'U', 47: 'V', 48: 'W', 49: 'X', 50: 'Y', 51: 'Z', 52: '[', 53: ']', 54: '^', 55: '_', 56: 'a', 57: 'b', 58: 'c', 59: 'd', 60: 'e', 61: 'f', 62: 'g', 63: 'h', 64: 'i', 65: 'j', 66: 'k', 67: 'l', 68: 'm', 69: 'n', 70: 'o', 71: 'p', 72: 'q', 73: 'r', 74: 's', 75: 't', 76: 'u', 77: 'v', 78: 'w', 79: 'x', 80: 'y', 81: 'z', 82: '|'}\n"
          ]
        }
      ],
      "source": [
        "index_to_char = dict((i,j) for i,j in enumerate(vocab))\n",
        "print(index_to_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtBuMUlDU3tl",
        "outputId": "86b7f9d4-db81-4a5f-a373-8b9ebb2177d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '\"' :   3,\n",
            "  '#' :   4,\n",
            "  \"'\" :   5,\n",
            "  '(' :   6,\n",
            "  ')' :   7,\n",
            "  ',' :   8,\n",
            "  '-' :   9,\n",
            "  '.' :  10,\n",
            "  '/' :  11,\n",
            "  '0' :  12,\n",
            "  '1' :  13,\n",
            "  '2' :  14,\n",
            "  '3' :  15,\n",
            "  '4' :  16,\n",
            "  '5' :  17,\n",
            "  '6' :  18,\n",
            "  '7' :  19,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print('{')\n",
        "for char,_ in zip(char_to_index, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char_to_index[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVVVg9OiU6Qo"
      },
      "outputs": [],
      "source": [
        "def vectorize_string(string):\n",
        "    vector = []\n",
        "    for char in string:\n",
        "#         print(type(char))\n",
        "        vector .append(char_to_index[char])\n",
        "    return np.array(vector)\n",
        "\n",
        "vectorized_songs = vectorize_string(songs_joined)\n",
        "# print(vectorized_songs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKhXOEi0U8zf",
        "outputId": "a090a00a-3a81-489c-a794-921fd56a94c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'X:1\\nT:Alex' ---- characters mapped to int ----> [49 22 13  0 45 22 26 67 60 79]\n"
          ]
        }
      ],
      "source": [
        "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
        "# check that vectorized_songs is a numpy array\n",
        "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3ffSzRSAknw"
      },
      "source": [
        "####Training Examples and Targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAkQZdSiU_PA",
        "outputId": "7f76ec35-3c22-4d00-cebd-4937fc65dc4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PASS] test_batch_func_types\n",
            "[PASS] test_batch_func_shapes\n",
            "[PASS] test_batch_func_next_step\n",
            "======\n",
            "[PASS] passed all tests!\n"
          ]
        }
      ],
      "source": [
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "    # the length of the vectorized songs string\n",
        "    n = vectorized_songs.shape[0] - 1\n",
        "    # randomly choose the starting indices for the examples in the training batch\n",
        "    idx = np.random.choice(n-seq_length, batch_size)\n",
        "    input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n",
        "    output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
        "\n",
        "    # x_batch, y_batch provide the true inputs and targets for network training\n",
        "    x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "    y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
        "    return x_batch, y_batch\n",
        "test_args = (vectorized_songs, 10, 2)\n",
        "if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_next_step(get_batch, test_args):\n",
        "    print(\"Could not pass tests\")\n",
        "else:\n",
        "    print(\"Passed all tests!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f20ld6zkVDEr",
        "outputId": "056bcb6f-81f6-401f-8251-441c212a5942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step   0\n",
            "  input: 14 ('2')\n",
            "  expected output: 58 ('c')\n",
            "Step   1\n",
            "  input: 58 ('c')\n",
            "  expected output: 1 (' ')\n",
            "Step   2\n",
            "  input: 1 (' ')\n",
            "  expected output: 27 ('B')\n",
            "Step   3\n",
            "  input: 27 ('B')\n",
            "  expected output: 14 ('2')\n",
            "Step   4\n",
            "  input: 14 ('2')\n",
            "  expected output: 59 ('d')\n"
          ]
        }
      ],
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
        "    print(\"Step {:3d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(index_to_char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(index_to_char[target_idx])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXHgB5S-BjTp"
      },
      "source": [
        "##LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezW9K6AsVFXC"
      },
      "outputs": [],
      "source": [
        "def LSTM(rnn_units):\n",
        "    return tf.keras.layers.LSTM(rnn_units, return_sequences=True, recurrent_initializer='glorot_uniform',\n",
        "                                recurrent_activation='sigmoid',stateful=True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RiEjhBaVHbv",
        "outputId": "66aa3971-fdf6-4268-b1c4-1c9ee053085f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (32, None, 256)           21248     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (32, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (32, None, 83)            85075     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,353,299\n",
            "Trainable params: 5,353,299\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def build_model_1(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "    # Layer 1: Embedding layer to transform indices into dense vectors\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "\n",
        "    # Layer 2: LSTM with `rnn_units` number of units.\n",
        "    LSTM(rnn_units),\n",
        "    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model_1(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lj2WsscVQWm",
        "outputId": "89f7f65f-84d5-43ac-b109-888dad1be3ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape:       (32, 100)  # (batch_size, sequence_length)\n",
            "Prediction shape:  (32, 100, 83) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
        "pred = model(x)\n",
        "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
        "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PRLtO4XBr1c"
      },
      "source": [
        "##Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J9PT-7ZVSLG",
        "outputId": "a98b7fc4-f63d-4645-f7c4-3a6d027c5ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (32, 100, 83)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.419444\n"
          ]
        }
      ],
      "source": [
        "def compute_loss(labels, logits):\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "    return loss\n",
        "\n",
        "example_batch_loss = compute_loss(y, pred)\n",
        "\n",
        "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t11Z0NH4BvTa"
      },
      "source": [
        "####Defining Hyperparameteres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWdWiEdbVXTr"
      },
      "outputs": [],
      "source": [
        "#Optimization parameters\n",
        "num_training_iterations = 10000\n",
        "batch_size = 4\n",
        "seq_length = 100\n",
        "learning_rate = 5e-3\n",
        "\n",
        "# Model parameters:\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "# Checkpoint location:\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MX0CsJ-KVZhf"
      },
      "outputs": [],
      "source": [
        "model = build_model_1(vocab_size, embedding_dim, rnn_units, batch_size)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "def train_step(x,y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(x)\n",
        "        loss = compute_loss(y, y_pred)\n",
        "    grad = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
        "    return loss.numpy().mean()\n",
        "losses = []\n",
        "for i in tqdm(range(0,num_training_iterations)):\n",
        "    x, y = get_batch(vectorized_songs, seq_length, batch_size)\n",
        "    loss = train_step(x,y)\n",
        "    losses.append(loss)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        model.save_weights(checkpoint_prefix)\n",
        "\n",
        "model.save_weights(checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mhPFWpjTQHID"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IZqETjB2QIWq"
      },
      "outputs": [],
      "source": [
        "model = build_model_1(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvTyn7v9QI0N"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string, generation_length=1000):\n",
        "    input_eval = [char_to_index[i] for i in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "    model.reset_states()\n",
        "    tqdm._instances.clear()\n",
        "\n",
        "    for i in tqdm(range(generation_length)):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "#         print(predicted_id)\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(index_to_char[predicted_id])\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ozXEcrnLQKUW"
      },
      "outputs": [],
      "source": [
        "generated_text = generate_text(model, start_string=\"C\", generation_length=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W7lFmPWOQNpQ"
      },
      "outputs": [],
      "source": [
        "print(generated_text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MsTNNMqjQZ4l"
      },
      "outputs": [],
      "source": [
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
        "m = 0;\n",
        "for i, song in enumerate(generated_songs):\n",
        "  # Synthesize the waveform from a song\n",
        "    waveform = mdl.lab1.play_song(song)\n",
        "    m+=1\n",
        "    if waveform:\n",
        "        print(\"Generated song\", i)\n",
        "        ipythondisplay.display(waveform)\n",
        "        if m>3:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwgJrIX3-I76"
      },
      "source": [
        "##Saving and Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IYmrr62BjIMb"
      },
      "outputs": [],
      "source": [
        "model.save('LSTM_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ENokd-H19QfL"
      },
      "outputs": [],
      "source": [
        "music_model=tf.keras.models.load_model('/content/LSTM_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6rlZpieg9W2t"
      },
      "outputs": [],
      "source": [
        "music_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b2oiDpqy-esF"
      },
      "outputs": [],
      "source": [
        "demo_text = generate_text(model, start_string=\"E\", generation_length=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hDFkWkD0-i3r"
      },
      "outputs": [],
      "source": [
        "generated_songs = mdl.lab1.extract_song_snippet(demo_text)\n",
        "m = 0;\n",
        "for i, song in enumerate(generated_songs):\n",
        "    waveform = mdl.lab1.play_song(song)\n",
        "    m+=1\n",
        "    if waveform:\n",
        "        print(\"Generated song\", i)\n",
        "        ipythondisplay.display(waveform)\n",
        "        if m>3:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBF8762p-Chx"
      },
      "source": [
        "##Converting to TFlite Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pYX7XiLe-5gs"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(music_model)\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MTjAmH8cCBly"
      },
      "outputs": [],
      "source": [
        "with tf.io.gfile.GFile('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0LX9eSaE0TJ",
        "outputId": "122eddb8-cec2-4db2-82a0-11bfbda87c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pexpect/popen_spawn.py:60: DeprecationWarning: setDaemon() is deprecated, set the daemon attribute instead\n",
            "  self._read_thread.setDaemon(True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8h0tj4PE7yt",
        "outputId": "25405075-af94-4570-d4c0-567a64fcb6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "model1=tf.keras.models.load_model('/content/gdrive/MyDrive/PBL/LSTM_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2U9An7cFKbe",
        "outputId": "bc02e31c-26d5-4992-f838-4eec15b52080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:13<00:00, 74.68it/s]\n"
          ]
        }
      ],
      "source": [
        "demo_text1 = generate_text(model1, start_string=\"Z\", generation_length=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzoFWwdWFRAC"
      },
      "outputs": [],
      "source": [
        "generated_songs = mdl.lab1.extract_song_snippet(demo_text1)\n",
        "m = 0;\n",
        "for i, song in enumerate(generated_songs):\n",
        "  # Synthesize the waveform from a song\n",
        "    waveform = mdl.lab1.play_song(song)\n",
        "    m+=1\n",
        "  # If its a valid song (correct syntax), lets play it!\n",
        "    if waveform:\n",
        "        print(\"Generated song\", i)\n",
        "        ipythondisplay.display(waveform)\n",
        "        if m>3:\n",
        "            break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObLoz/PzJYrHyv4HWUgCZI",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}